# -*- coding: utf-8 -*-
"""Data_pipeline_with_Redis_wk8_project_Nancy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m4ldSuVbDh7oazRY0ABPsHQGcvibj0kS
"""

!pip install redis

import pandas as pd
import psycopg2
import redis

# Redis Cloud Instance Information
redis_host = 'redis-14735.c84.us-east-1-2.ec2.cloud.redislabs.com:14735'
redis_port ='15487'
redis_password ='test'

# Postgres Database Information
pg_host = '34.31.101.211'
pg_database = 'nancy_redisproj'
pg_user = 'nancyredis'
pg_password = 'test'

!curl ipecho.net/plain

# Redis Client Object
r = redis.Redis(host='redis-14735.c84.us-east-1-2.ec2.cloud.redislabs.com:14735', port=15487, password='test', ssl=True)

def extract_data():
    # Extract data from CSV file using pandas
    data = pd.read_csv('customer_call_logs.csv')
    
    # Cache data in Redis for faster retrieval
    redis_client.set('customer_call_logs', df.to_msgpack(compress='zlib'))

def transform_data():
    # Retrieve data from Redis cache
    data = pd.read_json(redis_client.get('customer_call_logs'))

    # Transform data (clean, structure, format)
    # Clean and structure data
    df = df.drop_duplicates()  # Remove duplicate rows
    df['duration_minutes'] = df['duration_seconds'] / 60  # Add a new column for duration in minutes
    df = df[['customer_id', 'call_date', 'duration_minutes', 'cost', 'destination']]  # Select relevant columns
    
    # Format data
    df['call_date'] = pd.to_datetime(df['call_date'], format='%Y-%m-%d %H:%M:%S')
    df['cost'] = df['cost'].apply(lambda x: round(x, 2))  # Round cost to 2 decimal places

    return transformed_data

def load_data():
    # Connect to Postgres database
    conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)

    # Create a cursor object
    cur = conn.cursor()

    # Create a table to store the data
    cur.execute('CREATE TABLE IF NOT EXISTS customer_call_logs (\
                 customer_id INT,\
                 call_cost_usd FLOAT,\
                 call_destination VARCHAR,\
                 call_date TIMESTAMP,\
                 call_duration_min FLOAT\
                 )')

# Insert the transformed data into the database
    for i, row in transformed_data.iterrows():
        cur.execute(f"INSERT INTO customer_call_logs (customer_id, call_cost_usd, call_destination, call_date, call_duration_min) VALUES ({row['customer_id']}, {row['call_cost_usd']}, '{row['call_destination']}', '{row['call_date']}', {row['call_duration_min']})")

# Commit the changes
    conn.commit()

# Close the cursor and connection
    cur.close()
    conn.close()

def data_pipeline():
    # Data pipeline function
    extract_data()
    transformed_data = transform_data()
    load_data(transformed_data)

if __name__ == '__main__':
# Run the data pipeline function
    data_pipeline()